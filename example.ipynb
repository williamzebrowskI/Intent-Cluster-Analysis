{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the process and code for clustering intent examples based on their semantic similarity. The aim is to group similar intent examples together to reduce model confusion and improve intent detection accuracy.\n",
    "\n",
    "## Process Overview\n",
    "\n",
    "The following steps illustrate the overall process of semantic intent similarity detection and model confusion reduction:\n",
    "\n",
    "1. **Data Standardization**:\n",
    "    - Normalize training examples to ensure consistent analysis.\n",
    "    \n",
    "2. **Advanced Semantic Processing**:\n",
    "    - Extract linguistic features using `spaCy` such as lemmas, parts of speech (POS), and named entities.\n",
    "    \n",
    "3. **Numerical Transformation via TF-IDF**:\n",
    "    - Convert text data into numerical vectors based on term importance.\n",
    "    \n",
    "4. **Cosine Similarity Calculation**:\n",
    "    - Calculate the cosine similarity between vectors to generate a similarity matrix.\n",
    "    \n",
    "5. **DBSCAN Clustering Process**:\n",
    "    - Cluster intent examples using DBSCAN (Density-Based Spatial Clustering of Applications with Noise).\n",
    "    \n",
    "6. **Output of Clusters**:\n",
    "    - Group similar intent examples together, providing insights into which examples are closely related in terms of their semantic content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy scikit-learn pandas seaborn matplotlib\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example intent data\n",
    "intents = [\n",
    "    \"How do I reset my password?\",\n",
    "    \"What is the process to change my password?\",\n",
    "    \"Can you help me with password recovery?\",\n",
    "    \"What is the refund policy?\",\n",
    "    \"How can I get a refund?\",\n",
    "    \"Tell me about your return policy.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Standardization and Advanced Semantic Processing\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    lemmas = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return ' '.join(lemmas)\n",
    "\n",
    "normalized_data = [preprocess(intent) for intent in intents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Transformation via TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(normalized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine Similarity Calculation\n",
    "similarity_matrix = cosine_similarity(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN Clustering Process\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=2, metric='cosine')\n",
    "clusters = dbscan.fit_predict(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Clusters\n",
    "clustered_intents = {}\n",
    "for cluster_id in np.unique(clusters):\n",
    "    clustered_intents[cluster_id] = [intents[i] for i in range(len(clusters)) if clusters[i] == cluster_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster -1:\n",
      "  - How do I reset my password?\n",
      "  - What is the process to change my password?\n",
      "  - Can you help me with password recovery?\n",
      "Cluster 0:\n",
      "  - What is the refund policy?\n",
      "  - How can I get a refund?\n",
      "  - Tell me about your return policy.\n"
     ]
    }
   ],
   "source": [
    "# Print the output clusters\n",
    "for cluster_id, cluster_intents in clustered_intents.items():\n",
    "    print(f\"Cluster {cluster_id}:\")\n",
    "    for intent in cluster_intents:\n",
    "        print(f\"  - {intent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output shows that similar intent examples are grouped together into clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
